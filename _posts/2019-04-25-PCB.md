---
layout:     post
title:      PCB简介
subtitle:   对进程调度的数据结构进行介绍
date:       2019-04-25
author:     LENKE
header-img: img/post-bg-mma-2.jpg
catalog:    true
tags:       markdown 
---

为了对进程进行管理，操作系统用一个数据结构来表示进程全部的信息。一般我们称这个数据结构为PCB，process control block，也叫进程描述符，在Linux中，用task_struct这个结构体来实现。下面是这个结构体包含的内容和对应的作用。由于这个结构体有惊人的594行（在最近的版本中），所以我省略了很多内容。

1. **PID**

   process identifier，意为进程标识符，用来区分不同的进程。要控制进程，首先得找得到这个进程，就像我们人有名字，但是也得有身份证号，名字可以重复，身份证号却是唯一的。所以无论你在哪里，只要你用身份证刷了什么联网的东西，xx可以很轻易地通过身份证号找到你。如果在Linux中运行一个程序，然后打开另一个终端再次运行这个程序，那么这两个进程的名字是一样的，但是pid却不一样，同样的，父进程fork出来的子进程也和父进程有着相同的名字。

2. **进程状态**

   volatile long state，常用的状态有：

   - TASK_RUNNING运行（就绪）：进程处于运行态或者正在就绪队列中排队
   - TASK_INTERRUPTIBLE阻塞：进程因为等待信号、资源等被阻塞，一旦等待条件成立，进程就会从阻塞转为就绪
   - TASK_STOPPED停止：进程收到特定信号后被中止
   - TASK_TRACED被跟踪：当对进程进行调试的时候，会进入这个状态
   - EXIT_ZOMBIE僵尸：进程已经终止，但是父进程还没有处理他的状态，导致无法结束
   - EXIT_DEAD死亡：进程结束

   进程的状态可以帮助我们控制进程，如果你今天不舒服，那你的朋友在知道的情况下肯定不会叫你出去玩。如果进程处于阻塞状态，那么操作系统不会对他进行调度。

3. **内核栈和thread_info**

   每一个（普通）进程都有两种运行状态，即内核态和用户态，按照之前[函数调用](https://imagoodman.github.io/2018/04/26/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E5%92%8C%E5%A0%86%E6%A0%88%E5%8F%98%E5%8C%96/)的内容，函数调用是要一个栈来储存信息的，然而内核态和用户态可以访问的内存地址空间不一样（为了安全，用户态进程无法访问内核态的地址空间，如果能访问，那么随便的进程都可以更改操作系统最重要的内容），用户态进程通过调用系统准备的系统调用函数进入内核态，这时为了函数调用、储存信息方便，需要用到栈。因此，每一个进程都有一个内核栈在内核空间，用户进程还有一个用户栈在用户空间。

   介绍完了内核栈的由来，下面是thread_info，这个结构体位于进程内核堆栈的栈底固定偏移量的地方，包含了一些进程参数和PCB的地址，方便内核知道现在的这个进程的信息。[函数调用](https://imagoodman.github.io/2018/04/26/%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%E5%92%8C%E5%A0%86%E6%A0%88%E5%8F%98%E5%8C%96/)提到esp指向了栈顶，如果此时把esp减去一定的偏移量，就得到了thread_info的地址，x86的某版本中是这样实现的：

   ```c
   static inline struct thread_info *current_thread_info(void)
   {
   	return (struct thread_info *)(current_top_of_stack() - THREAD_SIZE);
   }
   //这个THREAD_SIZE是个常量，每个进程的内核栈初始都有固定大小，栈底减去这个量就是当前进程的thread_info地址
   ```

   在内存空间中，内核栈和thread_info是储存在**一起的**，具体如下：

   ```c
   union thread_union
   {
       struct thread_info thread_info;		
       unsigned long stack[THREAD_SIZE/sizeof(long)]; 		
   };
   //这个联合体占据了8k的空间，即两个连续内存页面，THREAD_SIZE就是这个联合体的大小，thread_info在离栈底最远的地方，有风险在内核栈填满时被覆盖掉，而内核调用一般简单，不容易覆盖到这个52字节的数据
   //stack就一数组，没啥可介绍的
   struct thread_info {
   	struct task_struct	*task;		/*这就是task_struct的地址 main task structure */
   	__u32			flags;		/* low level flags */
   	__u32			status;		/* thread synchronous flags */
   	__u32			cpu;		/* current CPU */
   	mm_segment_t		addr_limit;
   	unsigned int		sig_on_uaccess_error:1;
   	unsigned int		uaccess_err:1;	/* uaccess failed */
   };
   //这个结构体储存的都是内核最经常访问或者需要快速访问的进程数据，如果这里没有，就找到task_struct再在里面找更加详细的数据
   ```

   用户空间中有task_struct->stack找到内核堆栈，用task_struct->mm->vm_area找到用户堆栈，陷入内核后又通过thread_info来快速访问或者间接访问task_struct里面的数据。

4. **进程标记**

   unsigned int flags，眼神好的朋友可能还记得thread_info里面有这个变量，他表示进程的状态信息，不是进程的运行状态，下面摘抄几个状态：

   ```c
   #define PF_EXITING      0x00000004      /* getting shut down */
   #define PF_FORKNOEXEC   0x00000040      /* forked but didn't exec */
   #define PF_WQ_WORKER    0x00000020      /* I'm a workqueue worker */
   #define PF_SUPERPRIV    0x00000100      /* used super-user privileges 超级用户权限就是这里表示的*/
   #define PF_SIGNALED     0x00000400      /* killed by a signal */
   #define PF_KTHREAD      0x00200000      /* I am a kernel thread */
   #define PF_SWAPWRITE    0x00800000      /* Allowed to write to swap */
   ```

5. **进程族亲**

   ```c
   /*
    * pointers to (original) parent process, youngest child, younger sibling,
    * older sibling, respectively.  (p->father can be replaced with
    * p->real_parent->pid)
    */
   struct task_struct __rcu *real_parent; /* real parent process */
   struct task_struct __rcu *parent; /* recipient of SIGCHLD, wait4() reports */
   /*
    * children/sibling forms the list of my natural children
    */
   struct list_head children;      /* list of my children */
   struct list_head sibling;       /* linkage in my parent's children list */
   struct task_struct *group_leader;       /* threadgroup leader */
   ```

   这个real_parent和parent我也是没有搞明白……可以确定的是，一般这两个是一个进程，real_parent是fork这个进程的进程，而parent是在这个进程结束后接收SIGCHLD信号的进程。

   children和sibling就很好理解了，就是这个进程的子进程和兄弟进程链表的首部。

   group_leader表示的是这个进程所属的进程组的老大、组长。

   Linux中进程逻辑上呈现树型，为了正确地对进程和他的父进程、子进程、兄弟进程进行操作，应该在每一个进程中都含有他们的task_struct的地址以方便寻找。

   ```c
   struct list_head {  
       struct list_head *next, *prev;  
   };  
   struct task_struct *process = (struct task_struct *)malloc(sizeof(struct task_struct));
   ...//进行初始化
   children = &(process->children->next)；//children就是process进程的孩子进程的PCB
   ```

   额外介绍一下这个list_head结构体，是用来创建双向链表的，这个结构体中没有储存正常的数据，只有两个地址，所以都是嵌在需要做双向链表的结构体中的，为了方便才专门做了一个结构体出来。

6. **ptrace**

   unsigned int ptrace，大概就是表示这个进程是否被跟踪，用来调试进程用的。ptrace = 1的时候，父进程会替代子进程接收信号（除了SIGKILL），因而子进程会阻塞，并且进入TASK_TRACED状态，此时父进程可以对子进程的内存空间和寄存器为所欲为，不仅可以查看还可以修改，父进程选择什么时候激活子进程。

7. **调度**

   Linux的调度是基于线程的，因为Linux的线程是内核线程。决定在众多运行的进程中，谁可以得到运行，这个过程就叫做进程的调度。

   ```c
   //优先级
   int prio, static_prio, normal_prio;
   unsigned int rt_priority;
   //调度算法
   unsigned int policy;
   ```

   进程有优先级之分，就好比年纪小的应该得到应有的照顾，所以需要有一个数字来判断到底多个进程中，谁应该先得到照顾，谁应该得到这个时刻的CPU青睐。

   因为调度算法要和数据结构结合，所以这里有四种不同的优先级，在不同的算法中起到不同的作用。

   |    字段     |                    描述                     |         范围         |
   | :---------: | :-----------------------------------------: | :------------------: |
   |    prio     |                 动态优先级                  |                      |
   | static_prio |           静态优先级，创建时分配            |       100-139        |
   | normal_prio | 常规优先级，根据算法和static_prio来计算得出 |                      |
   | rt_priority |                 实时优先级                  | 1-99,0表示非实时任务 |

   除了这四个，还有一个nice变量，可以通过一个系统调用来改变，这个变量很有意思，表示进程nice的程度，如果很nice的话，就会主动让出优先级，让别人先用，nice∈[-20,19]。UNIX是鼓励进程在自己不需要的时候去调用系统函数降低自己优先级的，但是呢，很少有人用就是了，毕竟大家都只希望别很nice。

   这几个字段的算法在不同的系统中各有不同，同一个系统的不同调度算法下计算也有不同，这里举出一种计算方法。

   MAX_RT_PRIO = 100

   static_prio = MAX_RT_PRIO+20+nice

   对于非实时任务，prio = normal_prio = static_prio

   对于实时任务，prio = normal_prio = MAX_RT_PRIO – 1 – rt_priority

   实时不实时是根据任务对实时性要求的性质来判定的，和其他几个优先级无关。prio才是调度器会使用的优先级，值越小，优先级越高。静态优先级（nice）和实时优先级是优先级计算的基础。

   ```c
   unsigned int policy;      //调度策略
   const struct sched_class *sched_class;
   struct sched_entity se;
   struct sched_rt_entity rt;
   cpumask_t cpus_allowed;
   
   #define SCHED_NORMAL            0
   #define SCHED_FIFO              1
   #define SCHED_RR                2
   #define SCHED_BATCH             3
   /* SCHED_ISO: reserved but not implemented yet */
   #define SCHED_IDLE              5
   #define SCHED_DEADLINE          6
   ```

   这里只介绍一个字段，policy，其他的请百度。policy有七个取值，分别代表了的含义如下，具体的内容也请百度。

   | 字段           | 描述                                                         |
   | -------------- | ------------------------------------------------------------ |
   | SCHED_NORMAL   | 用于普通进程，通过CFS（完全公平调度器）实现。                |
   | SCHED_BATCH    | SCHED_NORMAL的分化版本。采用分时策略，根据动态优先级(可用nice()API设置），分配 CPU 运算资源。在有实时进程存在时，实时进程优先调度。 |
   | SCHED_IDLE     | 优先级最低，在系统空闲时才跑这类进程。                       |
   | SCHED_FIFO     | 先入先出调度算法（实时调度策略），相同优先级的任务先到先服务，高优先级的任务可以抢占低优先级的任务。 |
   | SCHED_RR       | 轮流调度算法（实时调度策略），每个任务每次调度获得一个时间片（时间片长度根据优先级计算），相同优先级的任务当用完时间片会被放到队列尾部，以保证公平性，同样，高优先级的任务可以抢占低优先级的任务。 |
   | SCHED_DEADLINE | 实时进程调度策略，针对突发型计算，且对延迟和完成时间高度敏感的任务适用。基于Earliest Deadline First (EDF) 调度算法。 |

8. **进程的地址空间**

   首先还是那句话，要控制首先得找得到。要控制地址空间，一定要先找的到这片地址空间，而手段则是内存描述符。

   ```c
   struct mm_struct *mm, *active_mm;
   //因为一个内核进程是没有用户空间的，所以mm是NULL，
   //下面是部分mm的结构体细节
   struct mm_struct {
       //指向页表的目录
       pgd_t * pgd;
       //共享进程时的个数
       atomic_t mm_users;          /* How many users with user space? */
       //内存描述符的主使用计数器，采用引用计数的原理，当为0时代表无用户再次使用
       atomic_t mm_count;          /* How many references to "struct mm_struct" (users count as 1) */
       //线性区的个数
       int map_count;              /* number of VMAs */
       //进程拥有的最大页表数目
       unsigned long hiwater_rss;  /* High-watermark of RSS usage */、
       //进程线性区的最大页表数目
       unsigned long hiwater_vm;   /* High-water virtual memory usage */
       //进程地址空间的大小，锁住无法换页的个数，共享文件内存映射的页数，可执行内存映射中的页数
       unsigned long total_vm, locked_vm, shared_vm, exec_vm;
       //用户态堆栈的页数
       unsigned long stack_vm, reserved_vm, def_flags, nr_ptes;
       //维护代码段和数据段
       unsigned long start_code, end_code, start_data, end_data;
       //维护堆和栈
       unsigned long start_brk, brk, start_stack;
       //维护命令行参数，命令行参数的起始地址和最后地址，以及环境变量的起始地址和最后地址
       unsigned long arg_start, arg_end, env_start, env_end;
   };
   ```

   mm中含有进程的代码段、数据段等段的地址（虚拟地址），然后根据pgd_t * pgd指向的页表去把虚拟地址映射成为物理地址，就可以进行访问了。这里涉及内存调度的知识，按下不表。

   这里要强调的是mm和avtive_mm的区别。mm指向内存描述符，avtive_mm指向进程真正使用的内存描述符。对于普通进程，这两个结构是一样的，但是对于内核进程则有区别，mm是个NULL，表明自己的内核进程的身份，然后active_mm指向内存描述符。总得有办法来区别内核进程和用户进程，用一个指针（4字节）不能说很节约空间，但是在判断上很快，至少比int快。

   每个进程都有自己的页表，假如两个进程用了相同的虚拟地址，但是在不同的页表映射下，最后得到的物理地址也不同，即分配到的页框不同。但是内核空间没有这样的映射关系，对于32位的寻址空间来说，每个用户进程**分别**拥有自己的地址空间0-3G，而地址最高的1G是内核空间。只有进入内核态的用户进程和内核进程才有资格访问，并且，这1G是被大家**共享**的，所以内核进程也称**内核线程**，因为大家共用了内核的地址空间，这样的共用的一个表现就在页表上——都用的同一个页表。

   因为这个页表是公用的，所以内核进程没有必要去新创建一个页表，只用把active_mm指向父进程的active_mm就可以了，大家都用一个页表，省空间。这里的前提条件是：只有内核进程可以创建内核进程，而第一个内核进程的页表是初始化的时候硬写进去的。

9. **时间信息**

   用数个字段记录进程已经运行的时间，在用户态/内核态运行的时间，自愿/非自愿的进程切换次数，进程创建时间，进程睡眠时间等等。用于进程调度和记录进程信息。

10. **信号**

   软中断又称信号，在原理上，进程收到一个信号和CPU 收到一个中断是差不多的。我们熟悉的异步进程间通信实际上都是用了信号的。一般在进程被调度的时候，都要先检查有没有信号要处理，就像我们起床看看有没有消息要回复。

   ```c
   void sig_alarm()   
   {   
     exit(0);   
   }  
   int main(int argc, char *argv[])   
   {   
     signal(SIGALRM, sig_alarm);   
     alarm(10);   
     sleep(15);   
     printf("Hello World!\n");   
     return 0;   
   }  
   ```

   这个例子中，main先设定了收到SIGALRM就执行sig_alarm，然后设置10s后给自己发一个SIGALRM信号，随即sleep15s，在sleep过程中，收到了SIGALRM，于是调用sig_alarm函数，直接退出，因而没有打印hello world。

11. **文件**

    ```c
    /* file system info */  
        int link_count, total_link_count;  
    /* filesystem information */  
        struct fs_struct *fs;  
    /* open file information */  
        struct files_struct *files;  
    ```

    Linux系统文件是很重要的概念，这里fs指向了进程的fs_struct，files指向进程的files_struct。fs_struct描述了根目录的地址，当前工作目录的地址，进程打开新文件时的权限，共享该结构的进程数，以及其他的关于目录的信息。files_struct描述了当前打开的文件数量和文件描述符，共享该结构的进程数，以及其他的关于文件的信息。

    我们说进程是资源分配的单位，其中一个资源——文件的分配就体现在这里。不同的进程一般有不同的这几个结构，但是由于写时复制（新进程的PCB是直接用的父进程的PCB，在需要改变时才复制并改变），多个进程可能同时拥有同一个文件的控制权。还有就是线程并没有被分配资源，都是共用的父进程的，其中就包括了文件的分配。

12. **and...**

    还有些诸如中断和进程通信的就不详细写了，读者有兴趣可以去找找资料看。



---

参考资料：

[task_struct]: https://blog.csdn.net/gatieme/article/details/51383272
[ptrace]: https://blog.csdn.net/u012417380/article/details/60470075
[priority]: http://www.wowotech.net/process_management/process-priority.html

[mm和active_mm]: http://www.niugebbs.com/wangluohongrenguidi/1020988.html
[页表]: http://kdf5000.com/2017/03/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%A1%B5%E8%A1%A8%E7%9A%84%E7%AE%A1%E7%90%86/
[地址空间]: https://blog.csdn.net/wrx1721267632/article/details/50197335
[还是地址空间]: https://blog.csdn.net/li_boxue/article/details/49474275

